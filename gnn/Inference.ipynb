{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer thas de installar torch_geometric , torch i scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'myenv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/dandmarbasera/Downloads/GNN-Malware-Detector/myenv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "\n",
    "class MyGNN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(MyGNN, self).__init__()\n",
    "\n",
    "        # Capa de entrada\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "\n",
    "        # Capa oculta\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # Capa de salida\n",
    "        self.conv3 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index, edge_attr, batch = data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        # Aplicar capas GCN y funciones de activación\n",
    "        x = F.relu(self.conv1(edge_attr, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "\n",
    "        # Global pooling para obtener la salida del grafo\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Aplicar la función de activación adecuada para tu tarea\n",
    "        x = F.log_softmax(x, dim=1)  # Mantén F.log_softmax si es un problema de clasificación\n",
    "        # Ajustar la forma de la salida\n",
    "        x = x.unsqueeze(0)  # Añadir una dimensión extra\n",
    "        x = x.view(-1, num_classes)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los parámetros del modelo\n",
    "num_features = 7  # Reemplaza con el número real de características\n",
    "hidden_channels = 64  # Puedes ajustar este valor según sea necesario\n",
    "num_classes = 2  # Reemplaza con el número real de clases\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = MyGNN(num_features, hidden_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **INFERENCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, when you want to perform inference\n",
    "# Load the entire model\n",
    "loaded_model = torch.load('whole_graph_model.pth')\n",
    "\n",
    "# Make sure to set the model to evaluation mode if needed\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "network_packets_df = pd.read_csv('network_packets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Seleccionar todas las columnas excepto las especificadas\n",
    "\n",
    "# Eliminar null values\n",
    "network_packets_df = network_packets_df.fillna('Normal')\n",
    "network_packets_df = network_packets_df.replace(' ', 'Normal')\n",
    "\n",
    "# Columnas que quieres convertir\n",
    "columns_to_encode = ['state', 'proto', 'srcip', 'dstip']\n",
    "\n",
    "# Aplicar Label Encoding a train_df\n",
    "label_encoder_train = LabelEncoder()\n",
    "for column in columns_to_encode:\n",
    "    network_packets_df[column] = label_encoder_train.fit_transform(network_packets_df[column])\n",
    "\n",
    "def convertir_a_cero(valor):\n",
    "    return 0 if isinstance(valor, str) else valor\n",
    "\n",
    "# Aplicar la función a la columna deseada\n",
    "network_packets_df['sport'] = network_packets_df['sport'].apply(convertir_a_cero)\n",
    "network_packets_df['dsport'] = network_packets_df['dsport'].apply(convertir_a_cero)\n",
    "\n",
    "network_packets_df['sport'] = network_packets_df['sport'].astype('int64')\n",
    "network_packets_df['dsport'] = network_packets_df['dsport'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_packets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "# Procesar los nuevos datos\n",
    "edge_index_list = []\n",
    "edge_attr_features = ['proto', 'state', 'dur', 'sbytes', 'dbytes', 'sport', 'dsport']\n",
    "edge_attr_values = network_packets_df[edge_attr_features].to_numpy()\n",
    "\n",
    "for i in range(len(network_packets_df)):\n",
    "    edge_index_i = torch.tensor([network_packets_df.iloc[i]['srcip'], network_packets_df.iloc[i]['dstip']], dtype=torch.long)\n",
    "    edge_index_list.append(edge_index_i)\n",
    "\n",
    "edge_attr_list = [torch.tensor(edge_attr_i, dtype=torch.float) for edge_attr_i in edge_attr_values]\n",
    "\n",
    "# Assuming you don't have labels for new data (as it's inference)\n",
    "y = None\n",
    "\n",
    "# Create a list of Data objects\n",
    "new_data_processed = [Data(x=edge_index_list[i].view(1, -1),  # Adjust the shape as needed\n",
    "                            edge_index=edge_index_list[i].view(-1, 1),  # Adjust the shape as needed\n",
    "                            edge_attr=edge_attr_list[i].view(1, -1),\n",
    "                            y=y) for i in range(len(network_packets_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar inferencia en los nuevos datos\n",
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    for data in new_data_processed:\n",
    "        data.edge_index = data.edge_index.view(-1)\n",
    "        data.edge_index[0]= 0\n",
    "        data.edge_index[1]= 0\n",
    "        output = loaded_model(data)\n",
    "        probabilities = torch.sigmoid(output)\n",
    "        predictions = torch.argmax(probabilities, dim=1).int().item()\n",
    "        all_predictions.append(predictions)\n",
    "\n",
    "# 'all_predictions' ahora contiene las predicciones del modelo para los nuevos datos\n",
    "print(all_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
